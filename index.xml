<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ke Sun</title>
    <link>https://ke-sun.github.io/</link>
      <atom:link href="https://ke-sun.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Ke Sun</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ke-sun.github.io/images/icon_hu6d66f09efe310b8ad7f3209e7ee864ae_219506_512x512_fill_lanczos_center_2.png</url>
      <title>Ke Sun</title>
      <link>https://ke-sun.github.io/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://ke-sun.github.io/talk/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Belief Space Planning for Mobile Robots with Range Sensors using iLQG</title>
      <link>https://ke-sun.github.io/publication/sun-ral-2020/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/sun-ral-2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Stochastic Motion Planning</title>
      <link>https://ke-sun.github.io/project/stochastic-motion-planning/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/project/stochastic-motion-planning/</guid>
      <description>&lt;p&gt;This is my research project, which considers the problem of motion planning that handles system uncertainty.
The &amp;ldquo;official&amp;rdquo; name of the problem is stochastic control.
But, I think it paints a better picture to call it &lt;strong&gt;Stochastic Motion Planning&lt;/strong&gt; to remind us we are planning trajectories for vehicles instead of, for example, balancing a inverted pendulum.
(Although in theory, the two problems are not so different despite the dissimilarity in the systems.)&lt;/p&gt;
&lt;p&gt;The research is motivated by the wide adoption of (half of) the &lt;strong&gt;separation theorem&lt;/strong&gt; in practical applications.
The separation theorem allows control algorithms to assume the availability of perfect state knowledge.
It is true for linear systems with quadratic costs, beyond which, the theorem is hard to justify.
Unfortunately, almost all robotic systems that we are interested in are nonlinear, while few state estimation algorithm is able to estimate the state perfectly.
Failing to meet the assumption can jeopardize the reliability and safety of the system.&lt;/p&gt;
&lt;p&gt;My goal in this research project is to address the stochastic motion planning problem in a principled way by
(1) modeling it as a Partially Observable Markov Decision Process (POMDP), and
(2) develop algorithms therefor.&lt;/p&gt;
&lt;h2 id=&#34;belief-space-planning-using-ilqg&#34;&gt;&lt;strong&gt;Belief Space Planning using iLQG&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;In this work, we extend iterative Linear-Quadratic-Gaussian (iLQG) to solve the stochastic motion planning problem.
The specific task under consideration is to navigate a car-like robot with Lidar from point A to B in a known environment.&lt;/p&gt;
&lt;p&gt;This work addresses two limitations of &lt;a href=&#34;https://journals.sagepub.com/doi/abs/10.1177/0278364912456319&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;iLQG introduced by van den Burg&lt;/a&gt; that prevent its application to navigate common autonomous vehicles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cannot work with nondifferentiable motion and measurement models.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Measurement models for Lidars are often nondifferentiable because of the discontinuity in the environment.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Degenerate with sparse informative measurements.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Informative measurements from commonly used sensors, such as Lidars and cameras, are sparse because of the limited sensing range.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below highlights belief trajectories planned by our work and some other methods that can be also applied in practice to navigate a car-like robot with Lidar.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;./fr101_ilqr_traj.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;fr101_ml_ilqg_traj.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;fr101_ukf_ilqg_traj.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;iLQR&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ML-iLQG&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Modified-iLQG (our work)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;iLQR&lt;/strong&gt;: The trajectory is optimized with iLQR which only considers motion uncertainty while assumes perfect state infomration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;M-iLQG&lt;/strong&gt;: The trajectory is optimized with iLQG assuming maximum likelihood future measurements.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As the figure shows, the modified iLQG (our work) is able to actively drive the robot along the wall for more accurate localization.&lt;/p&gt;
&lt;p&gt;Related publication: &lt;a href=&#34;https://arxiv.org/abs/2102.05466&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Sun, RAL2021]&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;pomcp-a-general-pomdp-solver&#34;&gt;&lt;strong&gt;POMCP++: A General POMDP Solver&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Using iLQG to solve POMDPs is efficient in finding a local optimum.
Especially, once the solution is found offline, the time to generate control inputs online is negligible.&lt;/p&gt;
&lt;p&gt;However, iLQG comes with intrinsic limitations.
First, iLQG requires explicit formulations of the system models, which can be sometimes out of reach (like only generative models are available).
Second, iLQG requires the objective function to be second-order differentiable.
It could be unintuitive to define costs satisfying this property.
Further, it is often hard to babysit the parameters of various cost terms to achieve a desired trajectory (maybe this is a common headache for almost all LQR solutions).&lt;/p&gt;
&lt;p&gt;General POMDP solvers, like &lt;a href=&#34;http://www.cs.cmu.edu/~ggordon/jpineau-ggordon-thrun.ijcai03.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Pineau, IJCAI2013]&lt;/a&gt;, pose minimal assumptions on the system and task modeling, which address the aforementioned limitations of iLQG.
However, general POMDP solvers are often good for discrete systems (systems with finite discrete state, control and measurement spaces).
Few success has been reported in applying general POMDP solvers to continuous robotic systems, such as navigating a car-like robot with Lidar.&lt;/p&gt;
&lt;p&gt;In this work, we propose POMCP++ built upon &lt;a href=&#34;https://papers.nips.cc/paper/2010/hash/edfbe1afcf9246bb0d40eb4d8027d90f-Abstract.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;POMCP by Silver&lt;/a&gt;, which can be applied to continuous robotic systems. More specifically, we address the following limitations of POMCP:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Degenerate with continous measurement space.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With continous measurement space, POMCP degenerate to a shallow tree of depth one.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Over-optimistic in estimating values for state-dependent rollout policies.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This limitation does not exist for state-independent rollout policies, like a random rollout policy.
However, it is often desired to use a more &amp;ldquo;intelligent&amp;rdquo; rollout policy by leveraging domain knowledge.
As in the case of motion planning, we may use deterministic motion planning methods, such as A*, to generate rollout policies.
Such rollout policies are state-dependent.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below shows the comparison between POMCP++ and some other methods in a simulation.
The task is to navigate a car-like robot with Lidar from bottom left (gray dot) of the map to top right (green dot).
Since there is no obstacle in the map, we may expect the robot to actively approach the edges or corners to reduce its localization uncertainty. The blue and red paths are success and failure cases over 100 simulations.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;./special_map2.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;special_map2_path_dmpp.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;special_map2_path_despot.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;configuration&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;RHC&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;DESPOT&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;special_map2_path_pomcpow.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;img src=&#34;special_map2_path_pomcp.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;POMCPOW&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;POMCP++ (our work)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RHC&lt;/strong&gt;: (Receding Horizon Control) The method assumes separation principle. At every step, an action is planned based on the mode of the current belief.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/1609.03250&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DESPOT&lt;/a&gt;&lt;/strong&gt;: A state-of-the-art general POMDP solver for discrete systems.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.06196&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;POMCPOW&lt;/a&gt;&lt;/strong&gt;: Another work on improving POMCP for continuous systems.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As the figure shows, under POMCP++, the robot is able to reliably utilize the top right corner for better localization before approaching the goal. As a result, a higher success rate is attained.&lt;/p&gt;
&lt;p&gt;Related publication: &lt;a href=&#34;https://arxiv.org/abs/2011.11836&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Sun, TRO2021]&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;future-research-ideas&#34;&gt;&lt;strong&gt;Future Research Ideas&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Improve the efficiency of POMCP++.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Extend the work to motion planning in unknown environments.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Autonomous Driving</title>
      <link>https://ke-sun.github.io/project/autonomous-driving/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/project/autonomous-driving/</guid>
      <description>&lt;p&gt;This is an on-going research project funded by Qualcomm.
The goal of the project is to advance the motion/behavior planning algorithms for self-driving vehicles.&lt;/p&gt;
&lt;p&gt;As an initial step, we made the following assumptions to make the problem more accessible:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The traffic is a deterministic system.&lt;/li&gt;
&lt;li&gt;The behavior of agent vehicles (vehicles around the self-driving/ego vehicle) are known.
We assume agent vehicles are lane follows with acceleration modulated by an intelligent driver model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We proposed Feedback Enhanced Lattice Planner (FELP).
The contribution of the work were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We used feedback, instead of open-loop, motion primitives for the ego vehicle (thus the name of the method).
The lattice dimension to be searched is reduced, leading to a reduction in runtime complexity.&lt;/li&gt;
&lt;li&gt;We introduced two variants of FELP to further reduce the runtime complexity to polynomial time.&lt;/li&gt;
&lt;li&gt;We further proposed a directed graph map to model the structured road environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below is a video highlighting FELP working with CARLA simulator.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=TxMY1dvHFog&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/TxMY1dvHFog/hqdefault.jpg&#34; alt=&#34;Sun IROS2020&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Related publication:
&lt;a href=&#34;https://arxiv.org/abs/2007.05794&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Sun, IROS2020]&lt;/a&gt;
&lt;a href=&#34;https://github.com/KumarRobotics/conformal_lattice_planner&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Code]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the next step, we beg the question of modeling the stochasticity in traffic dynamics and planning motions for the ego vehicle therein.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fast Lightweight Autonomy</title>
      <link>https://ke-sun.github.io/project/fast-lightweight-autonomy/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/project/fast-lightweight-autonomy/</guid>
      <description>&lt;p&gt;The project was funded by &lt;a href=&#34;https://www.darpa.mil/program/fast-lightweight-autonomy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DARPA (2015-2018)&lt;/a&gt;.
The goal was to understand the capability of MAVs in navigating unknown cluttered environments rapidly and autonomously using only onboard sensors (GPS-denied) and computation devices (cannot contact ground control for instructions).&lt;/p&gt;
&lt;p&gt;Maybe the PIs explained the project better than I did.
&lt;a href=&#34;https://www.youtube.com/watch?v=_UFabSMuz6w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/_UFabSMuz6w/hqdefault.jpg&#34; alt=&#34;FLA interview&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;UPenn (collaborated with OSRF and UZH) was one of the three teams. Below shows some video highlights of our group effort.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6eeetSVHXPk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/6eeetSVHXPk/hqdefault.jpg&#34; alt=&#34;Mohta ICRA2018&#34;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nVbZjbm4i84&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/nVbZjbm4i84/hqdefault.jpg&#34; alt=&#34;Watterson 2018&#34;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Related publications:
&lt;a href=&#34;https://arxiv.org/abs/1712.02052&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Mohta, JFR2017]&lt;/a&gt;
&lt;a href=&#34;https://arxiv.org/abs/1806.07053&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Mohta, ICRA2018]&lt;/a&gt;
&lt;a href=&#34;https://arxiv.org/abs/1809.07674&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Quigley, ICRA2019]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My major contribution in this project was the development of a stereo visual initial odometry, called S-MSCKF.
As the name suggests, S-MSCKF is an extension of MSCKF (originally proposed by Dr. Mourikis) to stereo cameras.
With stereo cameras, robustness of the odometry is improved (no longer need to wait for multiple frames to get the depth of a point feature).
S-MSCKF has been tested and proved to be reliable in various challenging scenarios, such as indoor-outdoor transition, feature-poverty scenes, fast motion (up to 18m/s).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=OXSB8Bze0cY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/OXSB8Bze0cY/hqdefault.jpg&#34; alt=&#34;Sun ICRA2018&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Related publication:
&lt;a href=&#34;https://arxiv.org/abs/1712.00036&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Sun, ICRA2018]&lt;/a&gt;
&lt;a href=&#34;https://github.com/KumarRobotics/msckf_vio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[Code]&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stochastic Motion Planning under Partial Observability for Mobile Robots with Continuous Range Measurements</title>
      <link>https://ke-sun.github.io/publication/sun-tro-2020/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/sun-tro-2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feedback Enhanced Motion Planning for Autonomous Vehicles</title>
      <link>https://ke-sun.github.io/publication/sun-iros-2020/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/sun-iros-2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trajectory optimization on manifolds with applications to quadrotor systems</title>
      <link>https://ke-sun.github.io/publication/watterson-ijrr-2020/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/watterson-ijrr-2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://ke-sun.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Open Vision Computer: An Integrated Sensing and Compute System for Mobile Robots</title>
      <link>https://ke-sun.github.io/publication/quigley-icra-2019/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/quigley-icra-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trajectory Optimization On Manifolds with Applications to SO(3) and R3XS2</title>
      <link>https://ke-sun.github.io/publication/watterson-rss-2018/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/watterson-rss-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dense 3-D Mapping with Spatial Correlation via Gaussian Filtering</title>
      <link>https://ke-sun.github.io/publication/sun-acc-2018/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/sun-acc-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Experiments in Fast, Autonomous, GPS-Denied Quadrotor Flight</title>
      <link>https://ke-sun.github.io/publication/mohta-icra-2018/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/mohta-icra-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fast, autonomous flight in GPS-denied and cluttered environments</title>
      <link>https://ke-sun.github.io/publication/mohta-jfr-2018/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/mohta-jfr-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Robust Stereo Visual Inertial Odometry for Fast Autonomous Flight</title>
      <link>https://ke-sun.github.io/publication/sun-ral-2018/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/sun-ral-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Planning Dynamically Feasible Trajectories for Quadrotors Using Safe Flight Corridors in 3-D Complex Environments</title>
      <link>https://ke-sun.github.io/publication/liu-ral-2017/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/liu-ral-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Welcome to Wowchemy, the website builder for Hugo</title>
      <link>https://ke-sun.github.io/post/getting-started/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/post/getting-started/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site&lt;/li&gt;
&lt;li&gt;The template can be modified and customised to suit your needs. It&amp;rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a &lt;strong&gt;no-code solution (write in Markdown and customize with YAML parameters)&lt;/strong&gt; and having &lt;strong&gt;flexibility to later add even deeper personalization with HTML and CSS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more&lt;/li&gt;
&lt;/ol&gt;


















&lt;figure id=&#34;figure-the-template-is-mobile-first-with-a-responsive-design-to-ensure-that-your-site-looks-stunning-on-every-device&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://raw.githubusercontent.com/wowchemy/wowchemy-hugo-modules/master/academic.png&#34; data-caption=&#34;The template is mobile first with a responsive design to ensure that your site looks stunning on every device.&#34;&gt;


  &lt;img src=&#34;https://raw.githubusercontent.com/wowchemy/wowchemy-hugo-modules/master/academic.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;get-started&#34;&gt;Get Started&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;üëâ &lt;a href=&#34;https://wowchemy.com/templates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Create a new site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üìö &lt;a href=&#34;https://wowchemy.com/docs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Personalize your site&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí¨ &lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chat with the &lt;strong&gt;Wowchemy community&lt;/strong&gt;&lt;/a&gt; or &lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Hugo community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üê¶ Twitter: &lt;a href=&#34;https://twitter.com/wowchemy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@wowchemy&lt;/a&gt; &lt;a href=&#34;https://twitter.com/GeorgeCushen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@GeorgeCushen&lt;/a&gt; &lt;a href=&#34;https://twitter.com/search?q=%28%23MadeWithWowchemy%20OR%20%23MadeWithAcademic%29&amp;amp;src=typed_query&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#MadeWithWowchemy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;üí° &lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Request a &lt;strong&gt;feature&lt;/strong&gt; or report a &lt;strong&gt;bug&lt;/strong&gt; for &lt;em&gt;Wowchemy&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;‚¨ÜÔ∏è &lt;strong&gt;Updating Wowchemy?&lt;/strong&gt; View the &lt;a href=&#34;https://wowchemy.com/docs/update/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Update Guide&lt;/a&gt; and &lt;a href=&#34;https://wowchemy.com/updates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;crowd-funded-open-source-software&#34;&gt;Crowd-funded open-source software&lt;/h2&gt;
&lt;p&gt;To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.&lt;/p&gt;
&lt;h3 id=&#34;-click-here-to-become-a-sponsor-and-help-support-wowchemys-future-httpswowchemycomplans&#34;&gt;&lt;a href=&#34;https://wowchemy.com/plans/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy&amp;rsquo;s future ‚ù§Ô∏è&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As a token of appreciation for sponsoring, you can &lt;strong&gt;unlock &lt;a href=&#34;https://wowchemy.com/plans/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;these&lt;/a&gt; awesome rewards and extra features ü¶Ñ‚ú®&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;ecosystem&#34;&gt;Ecosystem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-admin/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy Admin&lt;/a&gt;:&lt;/strong&gt; An admin tool to automatically import publications from BibTeX&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;inspiration&#34;&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Check out the latest &lt;strong&gt;demo&lt;/strong&gt;&lt;/a&gt; of what you&amp;rsquo;ll get in less than 10 minutes, or &lt;a href=&#34;https://wowchemy.com/user-stories/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;view the &lt;strong&gt;showcase&lt;/strong&gt;&lt;/a&gt; of personal, project, and business sites.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page builder&lt;/strong&gt; - Create &lt;em&gt;anything&lt;/em&gt; with &lt;a href=&#34;https://wowchemy.com/docs/page-builder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;widgets&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;elements&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edit any type of content&lt;/strong&gt; - Blog posts, publications, talks, slides, projects, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create content&lt;/strong&gt; in &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Markdown&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://wowchemy.com/docs/import/jupyter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Jupyter&lt;/strong&gt;&lt;/a&gt;, or &lt;a href=&#34;https://wowchemy.com/docs/install-locally/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;RStudio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plugin System&lt;/strong&gt; - Fully customizable &lt;a href=&#34;https://wowchemy.com/docs/customization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;color&lt;/strong&gt; and &lt;strong&gt;font themes&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Display Code and Math&lt;/strong&gt; - Code highlighting and &lt;a href=&#34;https://en.wikibooks.org/wiki/LaTeX/Mathematics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LaTeX math&lt;/a&gt; supported&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integrations&lt;/strong&gt; - &lt;a href=&#34;https://analytics.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Analytics&lt;/a&gt;, &lt;a href=&#34;https://disqus.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Disqus commenting&lt;/a&gt;, Maps, Contact Forms, and more!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beautiful Site&lt;/strong&gt; - Simple and refreshing one page design&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Industry-Leading SEO&lt;/strong&gt; - Help get your website found on search engines and social media&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Media Galleries&lt;/strong&gt; - Display your images and videos with captions in a customizable gallery&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile Friendly&lt;/strong&gt; - Look amazing on every screen with a mobile friendly version of your site&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-language&lt;/strong&gt; - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt; - Each author gets their own profile page&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Privacy Pack&lt;/strong&gt; - Assists with GDPR&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stand Out&lt;/strong&gt; - Bring your site to life with animation, parallax backgrounds, and scroll effects&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-Click Deployment&lt;/strong&gt; - No servers. No databases. Only files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;p&gt;Wowchemy and its templates come with &lt;strong&gt;automatic day (light) and night (dark) mode&lt;/strong&gt; built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the &lt;a href=&#34;https://academic-demo.netlify.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Demo&lt;/a&gt; to see it in action! Day/night mode can also be disabled by the site admin in &lt;code&gt;params.toml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/customization&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Choose a stunning &lt;strong&gt;theme&lt;/strong&gt; and &lt;strong&gt;font&lt;/strong&gt;&lt;/a&gt; for your site. Themes are fully customizable.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2016-present &lt;a href=&#34;https://georgecushen.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;George Cushen&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Released under the &lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/blob/master/LICENSE.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIT&lt;/a&gt; license.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Locomotive reduction for snake robots</title>
      <link>https://ke-sun.github.io/publication/xiao-icra-2015/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/xiao-icra-2015/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Adaptive-Profile Active Shape Model for Facial-Feature Detection</title>
      <link>https://ke-sun.github.io/publication/sun-icpr-2014/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/sun-icpr-2014/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A low-cost and robust optical flow CMOS camera for velocity estimation</title>
      <link>https://ke-sun.github.io/publication/sun-robio-2013/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>https://ke-sun.github.io/publication/sun-robio-2013/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
